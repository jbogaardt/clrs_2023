{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome back\n",
    "\n",
    "Welcome back! In our fifth session, we will:\n",
    "\n",
    "* Fit some linear models with statsmodels\n",
    "* Fit the same and a K-nearest neighbors model with scikit-learn\n",
    "\n",
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_triangle(line, url_stem = 'https://www.pirategrunt.com/paw/'):\n",
    "  url = url_stem + line + '_pos.csv'\n",
    "  df_out = pd.read_csv(url)\n",
    "  df_out.columns = [\n",
    "    'group_code', \n",
    "    'group_name', \n",
    "    'accident_year', \n",
    "    'development_year', \n",
    "    'lag',\n",
    "    'cumulative_incurred', \n",
    "    'cumulative_paid', \n",
    "    'bulk_loss', \n",
    "    'earned_premium',\n",
    "    'earned_premium_ceded',\n",
    "    'earned_premium_net', \n",
    "    'single',\n",
    "    'posted_reserve_97']\n",
    "  df_out['line'] = line\n",
    "  return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_triangle(df_triangle):\n",
    "  \"\"\"\n",
    "  Add prior cumulative, incremental and ldf columns for paid and incurred\n",
    "  \"\"\"\n",
    "  df_triangle = df_triangle.set_index(['line', 'group_code', 'accident_year', 'lag'])\n",
    "  group_cols = ['group_code', 'accident_year']\n",
    "  df_triangle[\n",
    "      ['prior_cumulative_paid', 'prior_cumulative_incurred']\n",
    "    ] = df_triangle.groupby(group_cols)[['cumulative_paid', 'cumulative_incurred']].shift()\n",
    "  df_triangle['incremental_paid'] = df_triangle.cumulative_paid - df_triangle.prior_cumulative_paid\n",
    "  df_triangle['incremental_incurred'] = df_triangle.cumulative_incurred - df_triangle.prior_cumulative_incurred\n",
    "  df_triangle['ldf_paid'] = df_triangle['cumulative_paid'] / df_triangle['prior_cumulative_paid']\n",
    "  df_triangle['ldf_incurred'] = df_triangle['cumulative_incurred'] / df_triangle['prior_cumulative_incurred']\n",
    "  # This will be important later\n",
    "  df_triangle = df_triangle.replace([np.inf, -np.inf], np.nan)\n",
    "  return df_triangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allstate = fetch_triangle('wkcomp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could run these two statements in either order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allstate = augment_triangle(df_allstate)\n",
    "df_allstate = df_allstate.query('group_name == \"Allstate Ins Co Grp\"').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways of thinking about modeling\n",
    "\n",
    "* `statsmodels`\n",
    "    * Textbook implementations\n",
    "    * Lovely diasnostics, from Akaike Information Criteria to Cook's distance\n",
    "* `scikit learn`\n",
    "    * Performance on a test set is the only diagnostic we need\n",
    "    * Unity of interface means loads of models. \n",
    "\n",
    "# `statsmodels`\n",
    "\n",
    "We can remember this with the easy pnuemonic: sm = Stephen Mildenhall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses a vector for Y and a (design) matrix for X. The OLS method will return a model object which we can later use to come up with a fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-14f3eb9f33ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m mdl_ols = sm.OLS(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mdf_allstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincremental_paid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mdf_allstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior_cumulative_paid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[0;32m    871\u001b[0m                  **kwargs):\n\u001b[1;32m--> 872\u001b[1;33m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       **kwargs)\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mexog_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exog contains inf or nans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mexog_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexog_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "mdl_ols = sm.OLS(\n",
    "  df_allstate.incremental_paid, \n",
    "  df_allstate.prior_cumulative_paid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'oh! What went wrong? We have some nans in our data. We can eliminate them by setting `missing = 'drop'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_ols = sm.OLS(\n",
    "  df_allstate.incremental_paid, \n",
    "  df_allstate.prior_cumulative_paid, \n",
    "  missing = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared (uncentered):</th>      <td>   0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   21.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th>          <td>1.17e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:04:46</td>     <th>  Log-Likelihood:    </th>          <td> -1026.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th>          <td>   2055.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    89</td>      <th>  BIC:               </th>          <td>   2057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid</th> <td>    0.0692</td> <td>    0.015</td> <td>    4.645</td> <td> 0.000</td> <td>    0.040</td> <td>    0.099</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45.224</td> <th>  Durbin-Watson:     </th> <td>   1.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  99.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.957</td> <th>  Prob(JB):          </th> <td>2.45e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.350</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared (uncentered):                   0.195\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.186\n",
       "Method:                 Least Squares   F-statistic:                              21.57\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):                    1.17e-05\n",
       "Time:                        10:04:46   Log-Likelihood:                         -1026.4\n",
       "No. Observations:                  90   AIC:                                      2055.\n",
       "Df Residuals:                      89   BIC:                                      2057.\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "prior_cumulative_paid     0.0692      0.015      4.645      0.000       0.040       0.099\n",
       "==============================================================================\n",
       "Omnibus:                       45.224   Durbin-Watson:                   1.209\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               99.521\n",
       "Skew:                           1.957   Prob(JB):                     2.45e-22\n",
       "Kurtosis:                       6.350   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols = mdl_ols.fit()\n",
    "\n",
    "fit_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1951055998610457\n",
      "prior_cumulative_paid    0.069235\n",
      "dtype: float64\n",
      "prior_cumulative_paid    4.644729\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(fit_ols.rsquared)\n",
    "print(fit_ols.params)\n",
    "print(fit_ols.tvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagnostics aren't great. We'll incorporate the lag, but we'll do it as a categorical variable. How do we do that? Easy, convert it to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allstate['lag_cat'] = df_allstate.index.get_level_values('lag').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain the methods and ignore the intermediate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2c650a7f0cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m fit_ols_z = sm.OLS(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mdf_allstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincremental_paid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mdf_allstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prior_cumulative_paid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lag_cat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m ).fit()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[0;32m    871\u001b[0m                  **kwargs):\n\u001b[1;32m--> 872\u001b[1;33m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       **kwargs)\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             self.endog, self.exog = self._convert_endog_exog(self.endog,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                                              self.exog)\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n\u001b[0m\u001b[0;32m    509\u001b[0m                              \"Check input data with np.asarray(data).\")\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "fit_ols_z = sm.OLS(\n",
    "  df_allstate.incremental_paid, \n",
    "  df_allstate[['prior_cumulative_paid', 'lag_cat']], \n",
    "  missing = 'drop'\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that doesn't work. The problem is that `OLS` wants a numeric matrix and we just fed it some character data. What we need is to create a \"one-hot encoding\" in a design matrix. We could do that from sratch, but this will take effort and could lead to mistakes\n",
    "\n",
    "There's another way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared:         </th> <td>   0.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>2.63e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:16</td>     <th>  Log-Likelihood:    </th> <td> -976.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   1973.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    80</td>      <th>  BIC:               </th> <td>   1998.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>-1.068e+04</td> <td> 5007.512</td> <td>   -2.133</td> <td> 0.036</td> <td>-2.06e+04</td> <td> -714.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.2]</th>          <td> 5.562e+04</td> <td> 6271.582</td> <td>    8.869</td> <td> 0.000</td> <td> 4.31e+04</td> <td> 6.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.3]</th>          <td> 3.225e+04</td> <td> 6048.764</td> <td>    5.332</td> <td> 0.000</td> <td> 2.02e+04</td> <td> 4.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.4]</th>          <td> 1.845e+04</td> <td> 5967.274</td> <td>    3.091</td> <td> 0.003</td> <td> 6572.448</td> <td> 3.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.5]</th>          <td> 1.124e+04</td> <td> 5937.400</td> <td>    1.892</td> <td> 0.062</td> <td> -580.133</td> <td> 2.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.6]</th>          <td> 6842.9401</td> <td> 5925.302</td> <td>    1.155</td> <td> 0.252</td> <td>-4948.787</td> <td> 1.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.7]</th>          <td> 4849.6661</td> <td> 5920.294</td> <td>    0.819</td> <td> 0.415</td> <td>-6932.093</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.8]</th>          <td> 2694.4088</td> <td> 5917.954</td> <td>    0.455</td> <td> 0.650</td> <td>-9082.696</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[T.9]</th>          <td> 1870.8194</td> <td> 5917.156</td> <td>    0.316</td> <td> 0.753</td> <td>-9904.697</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid</th> <td>    0.0745</td> <td>    0.017</td> <td>    4.330</td> <td> 0.000</td> <td>    0.040</td> <td>    0.109</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.513</td> <th>  Durbin-Watson:     </th> <td>   1.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  43.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.524</td> <th>  Prob(JB):          </th> <td>3.80e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.235</td> <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.569\n",
       "Method:                 Least Squares   F-statistic:                     14.07\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):           2.63e-13\n",
       "Time:                        10:05:16   Log-Likelihood:                -976.53\n",
       "No. Observations:                  90   AIC:                             1973.\n",
       "Df Residuals:                      80   BIC:                             1998.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept             -1.068e+04   5007.512     -2.133      0.036   -2.06e+04    -714.371\n",
       "lag_cat[T.2]           5.562e+04   6271.582      8.869      0.000    4.31e+04    6.81e+04\n",
       "lag_cat[T.3]           3.225e+04   6048.764      5.332      0.000    2.02e+04    4.43e+04\n",
       "lag_cat[T.4]           1.845e+04   5967.274      3.091      0.003    6572.448    3.03e+04\n",
       "lag_cat[T.5]           1.124e+04   5937.400      1.892      0.062    -580.133    2.31e+04\n",
       "lag_cat[T.6]           6842.9401   5925.302      1.155      0.252   -4948.787    1.86e+04\n",
       "lag_cat[T.7]           4849.6661   5920.294      0.819      0.415   -6932.093    1.66e+04\n",
       "lag_cat[T.8]           2694.4088   5917.954      0.455      0.650   -9082.696    1.45e+04\n",
       "lag_cat[T.9]           1870.8194   5917.156      0.316      0.753   -9904.697    1.36e+04\n",
       "prior_cumulative_paid     0.0745      0.017      4.330      0.000       0.040       0.109\n",
       "==============================================================================\n",
       "Omnibus:                       16.513   Durbin-Watson:                   1.369\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.380\n",
       "Skew:                          -0.524   Prob(JB):                     3.80e-10\n",
       "Kurtosis:                       6.235   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fit_ols_2 = smf.ols(\n",
    "  'incremental_paid ~ prior_cumulative_paid + lag_cat', \n",
    "  data = df_allstate.dropna()\n",
    ").fit()\n",
    "\n",
    "fit_ols_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do that without the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared:         </th> <td>   0.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>2.63e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:21</td>     <th>  Log-Likelihood:    </th> <td> -976.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   1973.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    80</td>      <th>  BIC:               </th> <td>   1998.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[10]</th>           <td>-1.068e+04</td> <td> 5007.512</td> <td>   -2.133</td> <td> 0.036</td> <td>-2.06e+04</td> <td> -714.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[2]</th>            <td> 4.494e+04</td> <td> 4237.587</td> <td>   10.605</td> <td> 0.000</td> <td> 3.65e+04</td> <td> 5.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[3]</th>            <td> 2.158e+04</td> <td> 4443.149</td> <td>    4.856</td> <td> 0.000</td> <td> 1.27e+04</td> <td> 3.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[4]</th>            <td> 7768.0627</td> <td> 4627.921</td> <td>    1.679</td> <td> 0.097</td> <td>-1441.793</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[5]</th>            <td>  556.0311</td> <td> 4754.800</td> <td>    0.117</td> <td> 0.907</td> <td>-8906.323</td> <td>    1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[6]</th>            <td>-3836.6979</td> <td> 4841.821</td> <td>   -0.792</td> <td> 0.430</td> <td>-1.35e+04</td> <td> 5798.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[7]</th>            <td>-5829.9719</td> <td> 4900.980</td> <td>   -1.190</td> <td> 0.238</td> <td>-1.56e+04</td> <td> 3923.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[8]</th>            <td>-7985.2293</td> <td> 4948.363</td> <td>   -1.614</td> <td> 0.111</td> <td>-1.78e+04</td> <td> 1862.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_cat[9]</th>            <td>-8808.8186</td> <td> 4980.366</td> <td>   -1.769</td> <td> 0.081</td> <td>-1.87e+04</td> <td> 1102.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid</th> <td>    0.0745</td> <td>    0.017</td> <td>    4.330</td> <td> 0.000</td> <td>    0.040</td> <td>    0.109</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.513</td> <th>  Durbin-Watson:     </th> <td>   1.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  43.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.524</td> <th>  Prob(JB):          </th> <td>3.80e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.235</td> <th>  Cond. No.          </th> <td>8.82e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.82e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.569\n",
       "Method:                 Least Squares   F-statistic:                     14.07\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):           2.63e-13\n",
       "Time:                        10:05:21   Log-Likelihood:                -976.53\n",
       "No. Observations:                  90   AIC:                             1973.\n",
       "Df Residuals:                      80   BIC:                             1998.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "lag_cat[10]           -1.068e+04   5007.512     -2.133      0.036   -2.06e+04    -714.371\n",
       "lag_cat[2]             4.494e+04   4237.587     10.605      0.000    3.65e+04    5.34e+04\n",
       "lag_cat[3]             2.158e+04   4443.149      4.856      0.000    1.27e+04    3.04e+04\n",
       "lag_cat[4]             7768.0627   4627.921      1.679      0.097   -1441.793     1.7e+04\n",
       "lag_cat[5]              556.0311   4754.800      0.117      0.907   -8906.323       1e+04\n",
       "lag_cat[6]            -3836.6979   4841.821     -0.792      0.430   -1.35e+04    5798.833\n",
       "lag_cat[7]            -5829.9719   4900.980     -1.190      0.238   -1.56e+04    3923.289\n",
       "lag_cat[8]            -7985.2293   4948.363     -1.614      0.111   -1.78e+04    1862.327\n",
       "lag_cat[9]            -8808.8186   4980.366     -1.769      0.081   -1.87e+04    1102.425\n",
       "prior_cumulative_paid     0.0745      0.017      4.330      0.000       0.040       0.109\n",
       "==============================================================================\n",
       "Omnibus:                       16.513   Durbin-Watson:                   1.369\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.380\n",
       "Skew:                          -0.524   Prob(JB):                     3.80e-10\n",
       "Kurtosis:                       6.235   Cond. No.                     8.82e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.82e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_3 = smf.ols(\n",
    "  'incremental_paid ~ 0 + prior_cumulative_paid + lag_cat', \n",
    "  data = df_allstate.dropna()\n",
    ").fit()\n",
    "\n",
    "fit_ols_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept was subsuming the lag 10 variable. What we REALLY want is an interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared (uncentered):</th>      <td>   0.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   52.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th>          <td>5.23e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:31</td>     <th>  Log-Likelihood:    </th>          <td> -950.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th>          <td>   1918.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    81</td>      <th>  BIC:               </th>          <td>   1941.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[10]</th> <td>    0.0088</td> <td>    0.016</td> <td>    0.545</td> <td> 0.588</td> <td>   -0.023</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[2]</th>  <td>    1.1569</td> <td>    0.069</td> <td>   16.802</td> <td> 0.000</td> <td>    1.020</td> <td>    1.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[3]</th>  <td>    0.3283</td> <td>    0.031</td> <td>   10.537</td> <td> 0.000</td> <td>    0.266</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[4]</th>  <td>    0.1466</td> <td>    0.023</td> <td>    6.279</td> <td> 0.000</td> <td>    0.100</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[5]</th>  <td>    0.0865</td> <td>    0.020</td> <td>    4.252</td> <td> 0.000</td> <td>    0.046</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[6]</th>  <td>    0.0540</td> <td>    0.019</td> <td>    2.886</td> <td> 0.005</td> <td>    0.017</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[7]</th>  <td>    0.0401</td> <td>    0.018</td> <td>    2.263</td> <td> 0.026</td> <td>    0.005</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[8]</th>  <td>    0.0263</td> <td>    0.017</td> <td>    1.543</td> <td> 0.127</td> <td>   -0.008</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[9]</th>  <td>    0.0230</td> <td>    0.017</td> <td>    1.386</td> <td> 0.170</td> <td>   -0.010</td> <td>    0.056</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.282</td> <th>  Durbin-Watson:     </th> <td>   2.051</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 533.073</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.071</td> <th>  Prob(JB):          </th> <td>1.76e-116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.922</td> <th>  Cond. No.          </th> <td>    4.24</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared (uncentered):                   0.853\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.836\n",
       "Method:                 Least Squares   F-statistic:                              52.10\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):                    5.23e-30\n",
       "Time:                        10:05:31   Log-Likelihood:                         -950.01\n",
       "No. Observations:                  90   AIC:                                      1918.\n",
       "Df Residuals:                      81   BIC:                                      1941.\n",
       "Df Model:                           9                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "prior_cumulative_paid:lag_cat[10]     0.0088      0.016      0.545      0.588      -0.023       0.041\n",
       "prior_cumulative_paid:lag_cat[2]      1.1569      0.069     16.802      0.000       1.020       1.294\n",
       "prior_cumulative_paid:lag_cat[3]      0.3283      0.031     10.537      0.000       0.266       0.390\n",
       "prior_cumulative_paid:lag_cat[4]      0.1466      0.023      6.279      0.000       0.100       0.193\n",
       "prior_cumulative_paid:lag_cat[5]      0.0865      0.020      4.252      0.000       0.046       0.127\n",
       "prior_cumulative_paid:lag_cat[6]      0.0540      0.019      2.886      0.005       0.017       0.091\n",
       "prior_cumulative_paid:lag_cat[7]      0.0401      0.018      2.263      0.026       0.005       0.075\n",
       "prior_cumulative_paid:lag_cat[8]      0.0263      0.017      1.543      0.127      -0.008       0.060\n",
       "prior_cumulative_paid:lag_cat[9]      0.0230      0.017      1.386      0.170      -0.010       0.056\n",
       "==============================================================================\n",
       "Omnibus:                       31.282   Durbin-Watson:                   2.051\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              533.073\n",
       "Skew:                           0.071   Prob(JB):                    1.76e-116\n",
       "Kurtosis:                      14.922   Cond. No.                         4.24\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_cl = smf.ols(\n",
    "  'incremental_paid ~ 0 + prior_cumulative_paid:lag_cat', \n",
    "  data = df_allstate.dropna()\n",
    ").fit()\n",
    "\n",
    "fit_ols_cl.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use patsy to create a design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prior_cumulative_paid:lag_cat[10]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[2]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[3]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[4]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[5]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[6]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[7]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[8]</th>\n",
       "      <th>prior_cumulative_paid:lag_cat[9]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <th>group_code</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>lag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">wkcomp</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">86</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1988</th>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70571.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220744.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prior_cumulative_paid:lag_cat[10]  \\\n",
       "line   group_code accident_year lag                                      \n",
       "wkcomp 86         1988          2                                  0.0   \n",
       "                                3                                  0.0   \n",
       "                                4                                  0.0   \n",
       "                                5                                  0.0   \n",
       "                                6                                  0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[2]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                             70571.0   \n",
       "                                3                                 0.0   \n",
       "                                4                                 0.0   \n",
       "                                5                                 0.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[3]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                            155905.0   \n",
       "                                4                                 0.0   \n",
       "                                5                                 0.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[4]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                                 0.0   \n",
       "                                4                            220744.0   \n",
       "                                5                                 0.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[5]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                                 0.0   \n",
       "                                4                                 0.0   \n",
       "                                5                            251595.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[6]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                                 0.0   \n",
       "                                4                                 0.0   \n",
       "                                5                                 0.0   \n",
       "                                6                            274156.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[7]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                                 0.0   \n",
       "                                4                                 0.0   \n",
       "                                5                                 0.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[8]  \\\n",
       "line   group_code accident_year lag                                     \n",
       "wkcomp 86         1988          2                                 0.0   \n",
       "                                3                                 0.0   \n",
       "                                4                                 0.0   \n",
       "                                5                                 0.0   \n",
       "                                6                                 0.0   \n",
       "\n",
       "                                     prior_cumulative_paid:lag_cat[9]  \n",
       "line   group_code accident_year lag                                    \n",
       "wkcomp 86         1988          2                                 0.0  \n",
       "                                3                                 0.0  \n",
       "                                4                                 0.0  \n",
       "                                5                                 0.0  \n",
       "                                6                                 0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices(\n",
    "  'incremental_paid ~ 0 + prior_cumulative_paid:lag_cat', \n",
    "  data = df_allstate.dropna(),\n",
    "  return_type='dataframe')\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared (uncentered):</th>      <td>   0.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   52.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th>          <td>5.23e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:39</td>     <th>  Log-Likelihood:    </th>          <td> -950.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th>          <td>   1918.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    81</td>      <th>  BIC:               </th>          <td>   1941.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[10]</th> <td>    0.0088</td> <td>    0.016</td> <td>    0.545</td> <td> 0.588</td> <td>   -0.023</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[2]</th>  <td>    1.1569</td> <td>    0.069</td> <td>   16.802</td> <td> 0.000</td> <td>    1.020</td> <td>    1.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[3]</th>  <td>    0.3283</td> <td>    0.031</td> <td>   10.537</td> <td> 0.000</td> <td>    0.266</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[4]</th>  <td>    0.1466</td> <td>    0.023</td> <td>    6.279</td> <td> 0.000</td> <td>    0.100</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[5]</th>  <td>    0.0865</td> <td>    0.020</td> <td>    4.252</td> <td> 0.000</td> <td>    0.046</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[6]</th>  <td>    0.0540</td> <td>    0.019</td> <td>    2.886</td> <td> 0.005</td> <td>    0.017</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[7]</th>  <td>    0.0401</td> <td>    0.018</td> <td>    2.263</td> <td> 0.026</td> <td>    0.005</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[8]</th>  <td>    0.0263</td> <td>    0.017</td> <td>    1.543</td> <td> 0.127</td> <td>   -0.008</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[9]</th>  <td>    0.0230</td> <td>    0.017</td> <td>    1.386</td> <td> 0.170</td> <td>   -0.010</td> <td>    0.056</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.282</td> <th>  Durbin-Watson:     </th> <td>   2.051</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 533.073</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.071</td> <th>  Prob(JB):          </th> <td>1.76e-116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.922</td> <th>  Cond. No.          </th> <td>    4.24</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared (uncentered):                   0.853\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.836\n",
       "Method:                 Least Squares   F-statistic:                              52.10\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):                    5.23e-30\n",
       "Time:                        10:05:39   Log-Likelihood:                         -950.01\n",
       "No. Observations:                  90   AIC:                                      1918.\n",
       "Df Residuals:                      81   BIC:                                      1941.\n",
       "Df Model:                           9                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "prior_cumulative_paid:lag_cat[10]     0.0088      0.016      0.545      0.588      -0.023       0.041\n",
       "prior_cumulative_paid:lag_cat[2]      1.1569      0.069     16.802      0.000       1.020       1.294\n",
       "prior_cumulative_paid:lag_cat[3]      0.3283      0.031     10.537      0.000       0.266       0.390\n",
       "prior_cumulative_paid:lag_cat[4]      0.1466      0.023      6.279      0.000       0.100       0.193\n",
       "prior_cumulative_paid:lag_cat[5]      0.0865      0.020      4.252      0.000       0.046       0.127\n",
       "prior_cumulative_paid:lag_cat[6]      0.0540      0.019      2.886      0.005       0.017       0.091\n",
       "prior_cumulative_paid:lag_cat[7]      0.0401      0.018      2.263      0.026       0.005       0.075\n",
       "prior_cumulative_paid:lag_cat[8]      0.0263      0.017      1.543      0.127      -0.008       0.060\n",
       "prior_cumulative_paid:lag_cat[9]      0.0230      0.017      1.386      0.170      -0.010       0.056\n",
       "==============================================================================\n",
       "Omnibus:                       31.282   Durbin-Watson:                   2.051\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              533.073\n",
       "Skew:                           0.071   Prob(JB):                    1.76e-116\n",
       "Kurtosis:                      14.922   Cond. No.                         4.24\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_cl_2 = sm.OLS(\n",
    "  y,\n",
    "  X\n",
    ").fit()\n",
    "\n",
    "fit_ols_cl_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy to create a model with a different variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>incremental_paid</td> <th>  R-squared (uncentered):</th>      <td>   0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   85.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Aug 2021</td> <th>  Prob (F-statistic):</th>          <td>1.47e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:44</td>     <th>  Log-Likelihood:    </th>          <td> -930.47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th>          <td>   1879.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    81</td>      <th>  BIC:               </th>          <td>   1901.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[10]</th> <td>    0.0065</td> <td>    0.010</td> <td>    0.657</td> <td> 0.513</td> <td>   -0.013</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[2]</th>  <td>    0.2144</td> <td>    0.010</td> <td>   21.729</td> <td> 0.000</td> <td>    0.195</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[3]</th>  <td>    0.1321</td> <td>    0.010</td> <td>   13.387</td> <td> 0.000</td> <td>    0.112</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[4]</th>  <td>    0.0787</td> <td>    0.010</td> <td>    7.972</td> <td> 0.000</td> <td>    0.059</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[5]</th>  <td>    0.0515</td> <td>    0.010</td> <td>    5.217</td> <td> 0.000</td> <td>    0.032</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[6]</th>  <td>    0.0343</td> <td>    0.010</td> <td>    3.476</td> <td> 0.001</td> <td>    0.015</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[7]</th>  <td>    0.0260</td> <td>    0.010</td> <td>    2.634</td> <td> 0.010</td> <td>    0.006</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[8]</th>  <td>    0.0188</td> <td>    0.010</td> <td>    1.903</td> <td> 0.061</td> <td>   -0.001</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earned_premium_net:lag_cat[9]</th>  <td>    0.0162</td> <td>    0.010</td> <td>    1.641</td> <td> 0.105</td> <td>   -0.003</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>41.147</td> <th>  Durbin-Watson:     </th> <td>   1.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 146.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.442</td> <th>  Prob(JB):          </th> <td>1.47e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.548</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:       incremental_paid   R-squared (uncentered):                   0.905\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.894\n",
       "Method:                 Least Squares   F-statistic:                              85.32\n",
       "Date:                Tue, 24 Aug 2021   Prob (F-statistic):                    1.47e-37\n",
       "Time:                        10:05:44   Log-Likelihood:                         -930.47\n",
       "No. Observations:                  90   AIC:                                      1879.\n",
       "Df Residuals:                      81   BIC:                                      1901.\n",
       "Df Model:                           9                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "earned_premium_net:lag_cat[10]     0.0065      0.010      0.657      0.513      -0.013       0.026\n",
       "earned_premium_net:lag_cat[2]      0.2144      0.010     21.729      0.000       0.195       0.234\n",
       "earned_premium_net:lag_cat[3]      0.1321      0.010     13.387      0.000       0.112       0.152\n",
       "earned_premium_net:lag_cat[4]      0.0787      0.010      7.972      0.000       0.059       0.098\n",
       "earned_premium_net:lag_cat[5]      0.0515      0.010      5.217      0.000       0.032       0.071\n",
       "earned_premium_net:lag_cat[6]      0.0343      0.010      3.476      0.001       0.015       0.054\n",
       "earned_premium_net:lag_cat[7]      0.0260      0.010      2.634      0.010       0.006       0.046\n",
       "earned_premium_net:lag_cat[8]      0.0188      0.010      1.903      0.061      -0.001       0.038\n",
       "earned_premium_net:lag_cat[9]      0.0162      0.010      1.641      0.105      -0.003       0.036\n",
       "==============================================================================\n",
       "Omnibus:                       41.147   Durbin-Watson:                   1.941\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              146.593\n",
       "Skew:                           1.442   Prob(JB):                     1.47e-32\n",
       "Kurtosis:                       8.548   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_ep = smf.ols(\n",
    "  'incremental_paid ~ 0 + earned_premium_net:lag_cat',\n",
    "  data = df_allstate.dropna()\n",
    ").fit()\n",
    "\n",
    "fit_ols_ep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, earned premium is a better predictor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526976159298703\n",
      "0.9045827396643866\n"
     ]
    }
   ],
   "source": [
    "print(fit_ols_cl.rsquared)\n",
    "print(fit_ols_ep.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_year\n",
       "1988    228327.203149\n",
       "1989    216475.349552\n",
       "1990    162143.074683\n",
       "1991    181613.894389\n",
       "1992    146165.919971\n",
       "1993    116294.505852\n",
       "1994    100865.694586\n",
       "1995     84661.220281\n",
       "1996     53963.242043\n",
       "1997      4425.501799\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_cl.predict(df_allstate.dropna()).groupby('accident_year').sum()\n",
    "fit_ols_ep.predict(df_allstate.dropna()).groupby('accident_year').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a GLM\n",
    "\n",
    "As with R, simply swap out the function and use the same input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>incremental_paid</td> <th>  No. Observations:  </th>   <td>    90</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>   <td>    81</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>   <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th>  <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td>    -inf</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 24 Aug 2021</td> <th>  Deviance:          </th> <td>4.1136e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:06:05</td>     <th>  Pearson chi2:      </th>  <td>3.01e+08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[10]</th> <td> 2.738e-05</td> <td> 3.21e-08</td> <td>  853.411</td> <td> 0.000</td> <td> 2.73e-05</td> <td> 2.74e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[2]</th>  <td>    0.0002</td> <td> 2.51e-08</td> <td> 6914.726</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[3]</th>  <td> 7.613e-05</td> <td> 1.44e-08</td> <td> 5286.657</td> <td> 0.000</td> <td> 7.61e-05</td> <td> 7.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[4]</th>  <td> 5.188e-05</td> <td> 1.35e-08</td> <td> 3837.084</td> <td> 0.000</td> <td> 5.19e-05</td> <td> 5.19e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[5]</th>  <td> 4.375e-05</td> <td> 1.44e-08</td> <td> 3036.365</td> <td> 0.000</td> <td> 4.37e-05</td> <td> 4.38e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[6]</th>  <td> 3.865e-05</td> <td> 1.61e-08</td> <td> 2401.191</td> <td> 0.000</td> <td> 3.86e-05</td> <td> 3.87e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[7]</th>  <td> 3.581e-05</td> <td> 1.73e-08</td> <td> 2067.817</td> <td> 0.000</td> <td> 3.58e-05</td> <td> 3.58e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[8]</th>  <td> 3.305e-05</td> <td> 2.02e-08</td> <td> 1633.935</td> <td> 0.000</td> <td>  3.3e-05</td> <td> 3.31e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prior_cumulative_paid:lag_cat[9]</th>  <td> 3.182e-05</td> <td> 2.08e-08</td> <td> 1527.062</td> <td> 0.000</td> <td> 3.18e-05</td> <td> 3.19e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:       incremental_paid   No. Observations:                   90\n",
       "Model:                            GLM   Df Residuals:                       81\n",
       "Model Family:                 Poisson   Df Model:                            8\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                   -inf\n",
       "Date:                Tue, 24 Aug 2021   Deviance:                   4.1136e+06\n",
       "Time:                        10:06:05   Pearson chi2:                 3.01e+08\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================================\n",
       "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "prior_cumulative_paid:lag_cat[10]  2.738e-05   3.21e-08    853.411      0.000    2.73e-05    2.74e-05\n",
       "prior_cumulative_paid:lag_cat[2]      0.0002   2.51e-08   6914.726      0.000       0.000       0.000\n",
       "prior_cumulative_paid:lag_cat[3]   7.613e-05   1.44e-08   5286.657      0.000    7.61e-05    7.62e-05\n",
       "prior_cumulative_paid:lag_cat[4]   5.188e-05   1.35e-08   3837.084      0.000    5.19e-05    5.19e-05\n",
       "prior_cumulative_paid:lag_cat[5]   4.375e-05   1.44e-08   3036.365      0.000    4.37e-05    4.38e-05\n",
       "prior_cumulative_paid:lag_cat[6]   3.865e-05   1.61e-08   2401.191      0.000    3.86e-05    3.87e-05\n",
       "prior_cumulative_paid:lag_cat[7]   3.581e-05   1.73e-08   2067.817      0.000    3.58e-05    3.58e-05\n",
       "prior_cumulative_paid:lag_cat[8]   3.305e-05   2.02e-08   1633.935      0.000     3.3e-05    3.31e-05\n",
       "prior_cumulative_paid:lag_cat[9]   3.182e-05   2.08e-08   1527.062      0.000    3.18e-05    3.19e-05\n",
       "=====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_pois = sm.GLM(y, X, family=sm.families.Poisson())\n",
    "fit_pois = mdl_pois.fit()\n",
    "fit_pois.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior_cumulative_paid:lag_cat[10]    1.000027\n",
       "prior_cumulative_paid:lag_cat[2]     1.000173\n",
       "prior_cumulative_paid:lag_cat[3]     1.000076\n",
       "prior_cumulative_paid:lag_cat[4]     1.000052\n",
       "prior_cumulative_paid:lag_cat[5]     1.000044\n",
       "prior_cumulative_paid:lag_cat[6]     1.000039\n",
       "prior_cumulative_paid:lag_cat[7]     1.000036\n",
       "prior_cumulative_paid:lag_cat[8]     1.000033\n",
       "prior_cumulative_paid:lag_cat[9]     1.000032\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(fit_pois.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO switch this up so that coefficients are on a non-log scale -->\n",
    "\n",
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "`sklearn` is the defacto standard Machine Learning API for Python.  Other libraries yield to the simplicity of its API. \n",
    "\n",
    "* Want to do some Keras Deep learning?  No problem, just use `keras.wrappers.scikit_learn`\n",
    "* XGBoost anyone?  Use: `xgboost.sklearn`\n",
    "* Don't want to learn the syntax for the Light GBM? `lightgbm.sklearn` to the rescue.\n",
    "* Natural langauge processing requires unique functionality, right? Nope, `nltk.classify.scikitlearn`\n",
    "\n",
    "Estimators are the building block of scikit-learn. Almost everything is an estimator. All estimators have fit() methods. Most have either a predict() or transform() method. Supervised techniques generally have a score() method as well.\n",
    "\n",
    "The basic ML workflow looks like this:\n",
    "\n",
    "from sklearn.EstimatorFamily import Estimator\n",
    "est = Estimator(hyperparameter_1, ... ,hyperparameter_n) # Create a model\n",
    "est.fit(X_train, y_train) # Fit the model\n",
    "est.score(X_test, y_test) # Evaluate model efficacy\n",
    "est.predict(X_test) # Create predictions\n",
    "\n",
    "## Importing estimators\n",
    "\n",
    "`from sklearn.EstimatorFamily import Estimator` is typically how you'd import an estimator.  Some examples are:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import RidgeRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "```\n",
    "\n",
    "## OLS\n",
    "\n",
    "Order of matrices is different than OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm_1 = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1059.02598083])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_1.score(X, y)\n",
    "lm_1.coef_\n",
    "lm_1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit learn will default to including an intercept. To get rid of it, we need to create a new method object and fit again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526976159298703"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_2 = LinearRegression(fit_intercept = False).fit(X, y)\n",
    "lm_2.score(X, y)\n",
    "fit_ols_cl_2.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is r^2 different? The parameters are the same. The issue is that we have a linear model without an intercept. The reasons are to do with math. Zzzzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior_cumulative_paid:lag_cat[10]    0.008844\n",
       "prior_cumulative_paid:lag_cat[2]     1.156867\n",
       "prior_cumulative_paid:lag_cat[3]     0.328289\n",
       "prior_cumulative_paid:lag_cat[4]     0.146553\n",
       "prior_cumulative_paid:lag_cat[5]     0.086466\n",
       "prior_cumulative_paid:lag_cat[6]     0.053993\n",
       "prior_cumulative_paid:lag_cat[7]     0.040150\n",
       "prior_cumulative_paid:lag_cat[8]     0.026309\n",
       "prior_cumulative_paid:lag_cat[9]     0.023028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_2.coef_\n",
    "fit_ols_cl_2.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it puts your mind at ease, we can create an OLS fit and compare to the scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859835045522741"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ols_cl_inter = smf.ols(\n",
    "  'incremental_paid ~ 1 + prior_cumulative_paid:lag_cat', \n",
    "  data = df_allstate.dropna()\n",
    ").fit()\n",
    "\n",
    "fit_ols_cl_inter.rsquared\n",
    "lm_1.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parting thoughts about $r^2$:\n",
    "\n",
    "* Mostly used for OLS, though we can \"fake it\" by calculating correlation between observations and predictions.\n",
    "* Does not consider things like serial correlation and outliers\n",
    "* Absence of an intercept muddles the calculation in ways that your undergrad textbook doesn't describe\n",
    "* Can be altered through a linear transform\n",
    "* I think people like $r^2$ because it is an _absolute_, rather than a _relative_ measure of model quality.\n",
    "  * When you get to GLMs, you can kiss $r^2$ good bye.\n",
    "  * Low $r^2$ doesn't mean a _bad_ model. Also, high $r^2$ doesn't necessarily mean a _good_ model.\n",
    "  * Metrics like RMSE, or MAE are useful ways to evaluate a model. How close your model resembles your data feels sort of important!\n",
    "\n",
    "Moving on ...\n",
    "\n",
    "Let's look at something a bit more like machine learning.\n",
    "\n",
    "## Classifier\n",
    "\n",
    "Pull in all lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['wkcomp', 'ppauto', 'comauto', 'medmal', 'prodliab', 'othliab']\n",
    "\n",
    "df_triangles = []\n",
    "for line in lines:\n",
    "  df = fetch_triangle(line)\n",
    "  df = augment_triangle(df)\n",
    "  df_triangles.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will basically do a row bind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triangles = pd.concat(df_triangles, axis=0, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77900, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triangles.index.names\n",
    "df_triangles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheap and cheerful contingency table. Note that `othliab` is the plurality class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "line\n",
       "comauto     15800\n",
       "medmal       3400\n",
       "othliab     23900\n",
       "ppauto      14600\n",
       "prodliab     7000\n",
       "wkcomp      13200\n",
       "Name: group_name, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triangles.group_name.groupby('line').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is just the `line`. It's in an index, so we'll need to use `get_level_values()` to extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_triangles.index.get_level_values('line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is simply a couple of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_triangles[['ldf_paid', 'ldf_incurred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some data, let's classify. \n",
    "\n",
    "Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, \n",
    "  test_size = 0.25, \n",
    "  random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-5c86e507f322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmdl_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmdl_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                 X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    364\u001b[0m                                            multi_output=True)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mdl_knn = KNeighborsClassifier()\n",
    "mdl_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to impute for the weird values. Note that `SimpleImputer()` will NOT impute infinite values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-663b8510ed20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmdl_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmdl_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "mdl_knn.fit(imp.transform(X_train), y_train)\n",
    "mdl_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forgot to impute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3011039794608472"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_knn.score(imp.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 299,  392,  673,   36,   51, 1862],\n",
       "       [ 263,  810, 1058,   23,   19, 1498],\n",
       "       [ 238,  458, 1252,   23,   37, 1838],\n",
       "       [  43,   49,  154,   17,   11,  581],\n",
       "       [  53,   63,  397,   14,   40, 1194],\n",
       "       [ 285,  342, 1799,   58,   99, 3446]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, mdl_knn.predict(imp.transform(X_test)), labels = lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is easy to convert to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wkcomp</th>\n",
       "      <th>ppauto</th>\n",
       "      <th>comauto</th>\n",
       "      <th>medmal</th>\n",
       "      <th>prodliab</th>\n",
       "      <th>othliab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wkcomp</th>\n",
       "      <td>299</td>\n",
       "      <td>392</td>\n",
       "      <td>673</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppauto</th>\n",
       "      <td>263</td>\n",
       "      <td>810</td>\n",
       "      <td>1058</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comauto</th>\n",
       "      <td>238</td>\n",
       "      <td>458</td>\n",
       "      <td>1252</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmal</th>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>154</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prodliab</th>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>397</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othliab</th>\n",
       "      <td>285</td>\n",
       "      <td>342</td>\n",
       "      <td>1799</td>\n",
       "      <td>58</td>\n",
       "      <td>99</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wkcomp  ppauto  comauto  medmal  prodliab  othliab\n",
       "wkcomp       299     392      673      36        51     1862\n",
       "ppauto       263     810     1058      23        19     1498\n",
       "comauto      238     458     1252      23        37     1838\n",
       "medmal        43      49      154      17        11      581\n",
       "prodliab      53      63      397      14        40     1194\n",
       "othliab      285     342     1799      58        99     3446"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_knn = pd.DataFrame(\n",
    "  confusion_matrix(y_test, mdl_knn.predict(imp.transform(X_test)), labels = lines),\n",
    "  index = lines, \n",
    "  columns = lines)\n",
    "\n",
    "df_confusion_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wkcomp       1181\n",
      "ppauto       2114\n",
      "comauto      5333\n",
      "medmal        171\n",
      "prodliab      257\n",
      "othliab     10419\n",
      "dtype: int64\n",
      "19475\n",
      "(19475, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_confusion_knn.sum())\n",
    "print(df_confusion_knn.sum().sum())\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3093196405648267"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mdl_logistic = LogisticRegression() \n",
    "mdl_logistic.fit(imp.transform(X_train), y_train)\n",
    "\n",
    "mdl_logistic.score(imp.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did barely better than K-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wkcomp</th>\n",
       "      <th>ppauto</th>\n",
       "      <th>comauto</th>\n",
       "      <th>medmal</th>\n",
       "      <th>prodliab</th>\n",
       "      <th>othliab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wkcomp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prodliab</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othliab</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wkcomp  ppauto  comauto  medmal  prodliab  othliab\n",
       "wkcomp         0       0        0       0         0     3313\n",
       "ppauto         0       0        0       0         0     3671\n",
       "comauto        0       0        0       0         0     3846\n",
       "medmal         0       0        0       0         0      855\n",
       "prodliab       0       4        0       0         2     1755\n",
       "othliab        0       6        0       0         1     6022"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_logistic = pd.DataFrame(\n",
    "  confusion_matrix(y_test, mdl_logistic.predict(imp.transform(X_test)), labels = lines),\n",
    "  index = lines, \n",
    "  columns = lines)\n",
    "\n",
    "df_confusion_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well. This is embarrassing.\n",
    "\n",
    "## Maybe a subset of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_sub = ['medmal', 'ppauto', 'wkcomp']\n",
    "df_tri_subs = df_triangles.query(\"line in ('medmal', 'ppauto', 'wkcomp')\").copy()\n",
    "\n",
    "y = df_tri_subs.index.get_level_values('line')\n",
    "X = df_tri_subs[['ldf_paid', 'ldf_incurred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to impute again, because we have new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, \n",
    "  test_size = 0.25, \n",
    "  random_state = 1234)\n",
    "\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medmal</th>\n",
       "      <th>ppauto</th>\n",
       "      <th>wkcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>medmal</th>\n",
       "      <td>6</td>\n",
       "      <td>753</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppauto</th>\n",
       "      <td>0</td>\n",
       "      <td>3601</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wkcomp</th>\n",
       "      <td>3</td>\n",
       "      <td>3194</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        medmal  ppauto  wkcomp\n",
       "medmal       6     753      50\n",
       "ppauto       0    3601      66\n",
       "wkcomp       3    3194     127"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logistic.fit(imp.transform(X_train), y_train)\n",
    "mdl_logistic.score(imp.transform(X_test), y_test)\n",
    "\n",
    "df_confusion_logistic = pd.DataFrame(\n",
    "  confusion_matrix(y_test, mdl_logistic.predict(imp.transform(X_test)), labels = lines_sub),\n",
    "  index = lines_sub, \n",
    "  columns = lines_sub)\n",
    "\n",
    "df_confusion_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's change things a bit. If we pivot the LDFs, perhaps we can detect some signal in the fact that LDFs depend on age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(    'ldf_paid',  1),\n",
       "            (    'ldf_paid',  2),\n",
       "            (    'ldf_paid',  3),\n",
       "            (    'ldf_paid',  4),\n",
       "            (    'ldf_paid',  5),\n",
       "            (    'ldf_paid',  6),\n",
       "            (    'ldf_paid',  7),\n",
       "            (    'ldf_paid',  8),\n",
       "            (    'ldf_paid',  9),\n",
       "            (    'ldf_paid', 10),\n",
       "            ('ldf_incurred',  1),\n",
       "            ('ldf_incurred',  2),\n",
       "            ('ldf_incurred',  3),\n",
       "            ('ldf_incurred',  4),\n",
       "            ('ldf_incurred',  5),\n",
       "            ('ldf_incurred',  6),\n",
       "            ('ldf_incurred',  7),\n",
       "            ('ldf_incurred',  8),\n",
       "            ('ldf_incurred',  9),\n",
       "            ('ldf_incurred', 10)],\n",
       "           names=[None, 'lag'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tri_wide = df_tri_subs[['ldf_paid', 'ldf_incurred']].unstack('lag')\n",
    "df_tri_wide.head()\n",
    "\n",
    "df_tri_wide.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our newly structured data frame looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_tri_wide.drop(1, axis = 1, level = 1)\n",
    "\n",
    "y = df_tri_wide.index.get_level_values('line')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, \n",
    "  test_size = 0.2, \n",
    "  random_state = 1234)\n",
    "imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfannin.CASACT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logistic.fit(imp.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data?! Ugh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314102564102564"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_knn.fit(imp.transform(X_train), y_train)\n",
    "mdl_knn.score(imp.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medmal</th>\n",
       "      <th>ppauto</th>\n",
       "      <th>wkcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>medmal</th>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppauto</th>\n",
       "      <td>2</td>\n",
       "      <td>246</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wkcomp</th>\n",
       "      <td>8</td>\n",
       "      <td>139</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        medmal  ppauto  wkcomp\n",
       "medmal      36      29       7\n",
       "ppauto       2     246      45\n",
       "wkcomp       8     139     112"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_knn = pd.DataFrame(\n",
    "  confusion_matrix(y_test, mdl_knn.predict(imp.transform(X_test))),\n",
    "  index = lines_sub, \n",
    "  columns = lines_sub)\n",
    "\n",
    "df_confusion_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Has a similar feel to the `recipes` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_logistic = Pipeline(\n",
    "  steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "  ]\n",
    ")\n",
    "\n",
    "mdl_knn = Pipeline(\n",
    "  steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline looks pretty in HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e {color: black;background-color: white;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e pre{padding: 0;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-toggleable {background-color: white;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-estimator:hover {background-color: #d4ebff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-item {z-index: 1;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-parallel-item:only-child::after {width: 0;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-d369cf8a-1f4b-4f96-8d4e-584d6f4b3e0e\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"60c62b53-a7fe-4018-aa2f-d6e6a25a522c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"60c62b53-a7fe-4018-aa2f-d6e6a25a522c\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  MultiIndex([(    'ldf_paid',  2),\n",
       "            (    'ldf_paid',  3),\n",
       "            (    'ldf_paid',  4),\n",
       "            (    'ldf_paid',  5),\n",
       "            (    'ldf_paid',  6),\n",
       "            (    'ldf_paid',  7),\n",
       "            (    'ldf_paid',  8),\n",
       "            (    'ldf_paid',  9),\n",
       "            (    'ldf_paid', 10),\n",
       "            ('ldf_incurred',  2),\n",
       "            ('ldf_incurred',  3),\n",
       "            ('ldf_incurred',  4),\n",
       "            ('ldf_incurred',  5),\n",
       "            ('ldf_incurred',  6),\n",
       "            ('ldf_incurred',  7),\n",
       "            ('ldf_incurred',  8),\n",
       "            ('ldf_incurred',  9),\n",
       "            ('ldf_incurred', 10)],\n",
       "           names=[None, 'lag']))])),\n",
       "                ('classifier', KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7b00d078-6b6d-488e-a64a-1fca2117f108\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7b00d078-6b6d-488e-a64a-1fca2117f108\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 MultiIndex([(    'ldf_paid',  2),\n",
       "            (    'ldf_paid',  3),\n",
       "            (    'ldf_paid',  4),\n",
       "            (    'ldf_paid',  5),\n",
       "            (    'ldf_paid',  6),\n",
       "            (    'ldf_paid',  7),\n",
       "            (    'ldf_paid',  8),\n",
       "            (    'ldf_paid',  9),\n",
       "            (    'ldf_paid', 10),\n",
       "            ('ldf_incurred',  2),\n",
       "            ('ldf_incurred',  3),\n",
       "            ('ldf_incurred',  4),\n",
       "            ('ldf_incurred',  5),\n",
       "            ('ldf_incurred',  6),\n",
       "            ('ldf_incurred',  7),\n",
       "            ('ldf_incurred',  8),\n",
       "            ('ldf_incurred',  9),\n",
       "            ('ldf_incurred', 10)],\n",
       "           names=[None, 'lag']))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0ba0d2be-fdc6-4f79-be56-2a043dcfc985\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0ba0d2be-fdc6-4f79-be56-2a043dcfc985\">num</label><div class=\"sk-toggleable__content\"><pre>MultiIndex([(    'ldf_paid',  2),\n",
       "            (    'ldf_paid',  3),\n",
       "            (    'ldf_paid',  4),\n",
       "            (    'ldf_paid',  5),\n",
       "            (    'ldf_paid',  6),\n",
       "            (    'ldf_paid',  7),\n",
       "            (    'ldf_paid',  8),\n",
       "            (    'ldf_paid',  9),\n",
       "            (    'ldf_paid', 10),\n",
       "            ('ldf_incurred',  2),\n",
       "            ('ldf_incurred',  3),\n",
       "            ('ldf_incurred',  4),\n",
       "            ('ldf_incurred',  5),\n",
       "            ('ldf_incurred',  6),\n",
       "            ('ldf_incurred',  7),\n",
       "            ('ldf_incurred',  8),\n",
       "            ('ldf_incurred',  9),\n",
       "            ('ldf_incurred', 10)],\n",
       "           names=[None, 'lag'])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3a01552e-6309-4ad2-b8f3-1c660d36df99\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3a01552e-6309-4ad2-b8f3-1c660d36df99\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e82aad63-4421-4d5b-a1bf-c2a6085a14cb\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e82aad63-4421-4d5b-a1bf-c2a6085a14cb\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"91e8f1e5-bdba-48ca-ba2c-b4dc951e5ad0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"91e8f1e5-bdba-48ca-ba2c-b4dc951e5ad0\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  MultiIndex([(    'ldf_paid',  2),\n",
       "            (    'ldf_paid',  3),\n",
       "            (    'ldf_paid',  4),\n",
       "            (    'ldf_paid',  5),\n",
       "            (    'ldf_paid',  6),\n",
       "            (    'ldf_paid',  7),\n",
       "            (    'ldf_paid',  8),\n",
       "            (    'ldf_paid',  9),\n",
       "            (    'ldf_paid', 10),\n",
       "            ('ldf_incurred',  2),\n",
       "            ('ldf_incurred',  3),\n",
       "            ('ldf_incurred',  4),\n",
       "            ('ldf_incurred',  5),\n",
       "            ('ldf_incurred',  6),\n",
       "            ('ldf_incurred',  7),\n",
       "            ('ldf_incurred',  8),\n",
       "            ('ldf_incurred',  9),\n",
       "            ('ldf_incurred', 10)],\n",
       "           names=[None, 'lag']))])),\n",
       "                ('classifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "mdl_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty, but how does it run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfannin.CASACT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6137820512820513"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "mdl_logistic.fit(X_train, y_train)\n",
    "mdl_logistic.score(X_test, y_test)\n",
    "\n",
    "mdl_knn.fit(X_train, y_train)\n",
    "mdl_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58974359, 0.60737179, 0.58653846, 0.5849359 , 0.53525641])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(mdl_knn, X, y, cv=5)\n",
    "cross_val_score(mdl_logistic, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO variable importance -->\n",
    "\n",
    "## Wrapping up scikit-learn\n",
    "\n",
    "* Almost everything is an Estimator. They all have a fit method and depending on the nature of the estimator may also have a predict, score or transform method.\n",
    "* The API is standardized across estimator\n",
    "* A transformer is a special type of estimator that tranforms data for another Estimator\n",
    "* Cross-validation with Grid Search helps in hyperparameter selection\n",
    "* Pipelines are useful for composing a chain of Estimators.\n",
    "* The documentation is a goldmine of information"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
